{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as rs\n",
    "import boto\n",
    "import pandas as pd\n",
    "from config_file import file_bucket\n",
    "from config_file import temp_s3_bucket\n",
    "from config_file import schema\n",
    "from config_file import dbname\n",
    "from config_file import port\n",
    "from config_file import user\n",
    "from config_file import password\n",
    "from config_file import table_name\n",
    "from config_file import host_url\n",
    "from config_file import aws_access_key_id\n",
    "from config_file import aws_secret_access_key\n",
    "from config_file import incremental_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If incremental load = \"Y\"\n",
    "#take latest file from bucket and place it temp directory\n",
    "\n",
    "if incremental_load = \"Y\":\n",
    "    \n",
    "\n",
    "else:\n",
    "    place all files from rawdata to temp directory\n",
    "\n",
    "for all files in temp_directory\n",
    "    convert json file in to csv \n",
    "    \n",
    "delete all json files from temp_directory\n",
    "\n",
    "load it to redshift for each csv file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "gaierror",
     "evalue": "[Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d850d74f7981>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                       )\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfile_bucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_bucket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_bucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msub_bucket_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_bucket\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/20'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_modified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub_bucket_files\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\boto\\s3\\connection.py\u001b[0m in \u001b[0;36mget_bucket\u001b[1;34m(self, bucket_name, validate, headers)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_bucket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbucket_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\boto\\s3\\connection.py\u001b[0m in \u001b[0;36mhead_bucket\u001b[1;34m(self, bucket_name, headers)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \"\"\"\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HEAD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\boto\\s3\\connection.py\u001b[0m in \u001b[0;36mmake_request\u001b[1;34m(self, method, bucket, key, headers, data, query_args, sender, override_num_retries, retry_handler)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0moverride_num_retries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_num_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[0mretry_handler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\boto\\connection.py\u001b[0m in \u001b[0;36mmake_request\u001b[1;34m(self, method, path, headers, data, host, auth_path, sender, override_num_retries, params, retry_handler)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                                                     params, headers, data, host)\n\u001b[0;32m   1070\u001b[0m         return self._mexe(http_request, sender, override_num_retries,\n\u001b[1;32m-> 1071\u001b[1;33m                           retry_handler=retry_handler)\n\u001b[0m\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\boto\\connection.py\u001b[0m in \u001b[0;36m_mexe\u001b[1;34m(self, request, sender, override_num_retries, retry_handler)\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mBotoServerError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Please report this exception as a Boto Issue!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "# Connecting to S3 and listing all files\n",
    "\n",
    "s3_client = boto.connect_s3( \n",
    "                      aws_access_key_id=aws_access_key_id, \n",
    "                      aws_secret_access_key=aws_secret_access_key, \n",
    "                      \n",
    "                      )\n",
    "\n",
    "file_bucket = s3_client.get_bucket(file_bucket)\n",
    "sub_bucket_files = file_bucket.list(file_bucket+'/20') # we are excluding temp sirectory and limiting only directories json files\n",
    "l = [(file.last_modified, file) for file in sub_bucket_files] # taking file name and timestamp from file listing data\n",
    "\n",
    "if incremental_load == \"Y\": #if incremental load, take latest file and place on temp directory\n",
    "    latest_file_name = sorted(l, cmp=lambda x,y: cmp(x[0], y[0]))[-1][1] #sorted based on 2nd timestamp attribute and extracting latest one\n",
    "    latest_file_name.get_contents_to_filename(temp_s3_bucket + latest_file_name) # placing it on temp directory\n",
    "\n",
    "else: #take all files and place in temp directory\n",
    "    for file in l:\n",
    "        file[1].get_contents_to_filename(temp_s3_bucket + latest_file_name) # copying all files in temp directory for load\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get list of files which are placed in tempdirectory\n",
    "target_bucket = s3_client.get_bucket(temp_s3_bucket)\n",
    "\n",
    "for file_path in bucket.list():\n",
    "    \n",
    "        #option 1: load json file directly in redshift\n",
    "        # json file can be loaded in redshift \n",
    "\n",
    "        sql=\"\"\"copy {}.{} \n",
    "                from '{}'\\\n",
    "             credentials \\\n",
    "            'aws_access_key_id={};\n",
    "            aws_secret_access_key={}' \\\n",
    "            JSON 'auto' ACCEPTINVCHARS;commit;\"\"\"\\\n",
    "             .format(schema, table, file_path, aws_access_key_id, aws_secret_access_key)\n",
    "\n",
    "        con_url = \"dbname='{}'\\\n",
    "                    port='{}' \\\n",
    "                    user='{}' \\\n",
    "                    password='{}' \\\n",
    "                    host='{}'\"\\\n",
    "                  .format(dbname,port,user,password,host_url)  \n",
    "\n",
    "        con = rs.connect(con_url)\n",
    "\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(sql)\n",
    "        cursor.close()\n",
    "\n",
    "    \n",
    "    # Option 2 \n",
    "    #convert json file to csv using pandas\n",
    "    \n",
    "    df = pd.read_json(file_path) # reading json file\n",
    "    df.to_csv(file_path) #writing in csv file\n",
    "    \n",
    "    #load data in redshift\n",
    "    \n",
    "    sql=\"\"\"copy {}.{} \n",
    "                from '{}'\\\n",
    "             credentials \\\n",
    "            'aws_access_key_id={};\n",
    "            aws_secret_access_key={}' \\\n",
    "            DELIMITER ',' ACCEPTINVCHARS;commit;\"\"\"\\\n",
    "             .format(schema, table, file_path, aws_access_key_id, aws_secret_access_key)\n",
    "\n",
    "    con = rs.connect(con_url)\n",
    "\n",
    "    cursor = con.cursor()\n",
    "    cursor.execute(sql)\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete temp_directory\n",
    "\n",
    "for file_path in bucket.list():\n",
    "    bucket.delete_key(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
